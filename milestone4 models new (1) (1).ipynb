{"cells":[{"cell_type":"code","execution_count":1,"id":"01ef5bd0","metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-tt123-m.us-central1-f.c.thisisaproject-434114.internal:45927\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff0dc284bd0>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":2,"id":"c129e173","metadata":{},"outputs":[],"source":["from google.cloud import storage\n","from pyspark.sql.functions import col\n","from pyspark.ml.regression import RandomForestRegressor\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n","from pyspark.ml import Pipeline\n"]},{"cell_type":"code","execution_count":3,"id":"52bd1829","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+--------------------------+------+-----------+-----------+------------------------+-----------------------+-----------+------------------+-------------------------------------------------------------------+\n","|movie                     |rating|review_date|spoiler_tag|review_summary_sentiment|review_detail_sentiment|movie_index|movie_vector      |features                                                           |\n","+--------------------------+------+-----------+-----------+------------------------+-----------------------+-----------+------------------+-------------------------------------------------------------------+\n","|After Life (2019– )       |9.0   |3 May 2020 |0.0        |0.5633333333333334      |0.2727777777777778     |147.0      |(1001,[147],[1.0])|(1004,[148,1002,1003],[1.0,0.5633333333333334,0.2727777777777778]) |\n","|Special OPS (2020– )      |7.0   |3 May 2020 |0.0        |0.35714285714285715     |0.178125               |984.0      |(1001,[984],[1.0])|(1004,[985,1002,1003],[1.0,0.35714285714285715,0.178125])          |\n","|Iron Fist (2017–2018)     |9.0   |3 May 2020 |0.0        |1.0                     |0.2609375              |420.0      |(1001,[420],[1.0])|(1004,[421,1002,1003],[1.0,1.0,0.2609375])                         |\n","|Thappad (I) (2020)        |10.0  |3 May 2020 |0.0        |0.0                     |0.3333333333333333     |501.0      |(1001,[501],[1.0])|(1004,[502,1003],[1.0,0.3333333333333333])                         |\n","|After Life (2019– )       |10.0  |3 May 2020 |0.0        |0.21428571428571427     |0.4614583333333333     |147.0      |(1001,[147],[1.0])|(1004,[148,1002,1003],[1.0,0.21428571428571427,0.4614583333333333])|\n","|The Raikar Case (2020– )  |9.0   |3 May 2020 |1.0        |-0.4                    |0.0642857142857143     |927.0      |(1001,[927],[1.0])|(1004,[0,928,1002,1003],[1.0,1.0,-0.4,0.0642857142857143])         |\n","|After Life (2019– )       |9.0   |3 May 2020 |0.0        |0.5                     |0.33095238095238094    |147.0      |(1001,[147],[1.0])|(1004,[148,1002,1003],[1.0,0.5,0.33095238095238094])               |\n","|Sonic the Hedgehog (2020) |3.0   |3 May 2020 |0.0        |0.2                     |0.07011494252873565    |349.0      |(1001,[349],[1.0])|(1004,[350,1002,1003],[1.0,0.2,0.07011494252873565])               |\n","|The Wandering Earth (2019)|4.0   |3 May 2020 |1.0        |0.55                    |0.28961038961038965    |694.0      |(1001,[694],[1.0])|(1004,[0,695,1002,1003],[1.0,1.0,0.55,0.28961038961038965])        |\n","|The Chosen (2017– )       |10.0  |3 May 2020 |0.0        |1.0                     |0.1625                 |40.0       |(1001,[40],[1.0]) |(1004,[41,1002,1003],[1.0,1.0,0.1625])                             |\n","+--------------------------+------+-----------+-----------+------------------------+-----------------------+-----------+------------------+-------------------------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["sdf = spark.read.parquet(\"gs://imdbreviews-bucket/features/transformed_data_with_features.parquet\")\n","sdf.show(10, truncate=False)"]},{"cell_type":"code","execution_count":4,"id":"bd5d63f2","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- movie: string (nullable = true)\n"," |-- rating: double (nullable = true)\n"," |-- review_date: string (nullable = true)\n"," |-- spoiler_tag: double (nullable = true)\n"," |-- review_summary_sentiment: double (nullable = true)\n"," |-- review_detail_sentiment: double (nullable = true)\n"," |-- movie_index: double (nullable = true)\n"," |-- movie_vector: vector (nullable = true)\n"," |-- features: vector (nullable = true)\n","\n"]}],"source":["# Check schema to confirm the features column exists\n","sdf.printSchema()"]},{"cell_type":"code","execution_count":5,"id":"8144b833","metadata":{"scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: An illegal reflective access operation has occurred                    \n","WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.5.1.jar) to field java.nio.charset.Charset.name\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","24/12/03 01:56:34 WARN DAGScheduler: Broadcasting large task binary with size 1108.5 KiB\n","24/12/03 01:56:38 WARN DAGScheduler: Broadcasting large task binary with size 1451.6 KiB\n","24/12/03 01:56:43 WARN DAGScheduler: Broadcasting large task binary with size 1809.6 KiB\n","24/12/03 01:57:13 WARN DAGScheduler: Broadcasting large task binary with size 1108.5 KiB\n","24/12/03 01:57:17 WARN DAGScheduler: Broadcasting large task binary with size 1451.6 KiB\n","24/12/03 01:57:21 WARN DAGScheduler: Broadcasting large task binary with size 1809.6 KiB\n","24/12/03 01:57:26 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n","24/12/03 01:57:32 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n","24/12/03 01:57:38 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n","24/12/03 01:57:44 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n","24/12/03 01:57:51 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n","24/12/03 01:59:08 WARN DAGScheduler: Broadcasting large task binary with size 1368.8 KiB\n","24/12/03 01:59:15 WARN DAGScheduler: Broadcasting large task binary with size 1857.8 KiB\n","24/12/03 01:59:24 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/12/03 01:59:34 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n","24/12/03 02:00:23 WARN DAGScheduler: Broadcasting large task binary with size 1368.8 KiB\n","24/12/03 02:00:31 WARN DAGScheduler: Broadcasting large task binary with size 1857.8 KiB\n","24/12/03 02:00:40 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/12/03 02:00:49 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n","24/12/03 02:01:00 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n","24/12/03 02:01:12 WARN DAGScheduler: Broadcasting large task binary with size 4.9 MiB\n","24/12/03 02:01:24 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n","24/12/03 02:01:37 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n","24/12/03 02:01:54 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n","24/12/03 02:03:44 WARN DAGScheduler: Broadcasting large task binary with size 1237.1 KiB\n","24/12/03 02:03:55 WARN DAGScheduler: Broadcasting large task binary with size 1763.2 KiB\n","24/12/03 02:04:07 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/12/03 02:04:21 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n","24/12/03 02:04:36 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n","24/12/03 02:05:39 WARN DAGScheduler: Broadcasting large task binary with size 1237.1 KiB\n","24/12/03 02:05:51 WARN DAGScheduler: Broadcasting large task binary with size 1763.2 KiB\n","24/12/03 02:06:03 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/12/03 02:06:17 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n","24/12/03 02:06:33 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n","24/12/03 02:06:51 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n","24/12/03 02:07:09 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n","24/12/03 02:07:31 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n","24/12/03 02:07:53 WARN DAGScheduler: Broadcasting large task binary with size 10.5 MiB\n","24/12/03 02:08:17 WARN DAGScheduler: Broadcasting large task binary with size 12.3 MiB\n","24/12/03 02:09:19 WARN DAGScheduler: Broadcasting large task binary with size 1113.0 KiB\n","24/12/03 02:09:22 WARN DAGScheduler: Broadcasting large task binary with size 1430.1 KiB\n","24/12/03 02:09:25 WARN DAGScheduler: Broadcasting large task binary with size 1853.0 KiB\n","24/12/03 02:09:45 WARN DAGScheduler: Broadcasting large task binary with size 1113.0 KiB\n","24/12/03 02:09:48 WARN DAGScheduler: Broadcasting large task binary with size 1430.1 KiB\n","24/12/03 02:09:51 WARN DAGScheduler: Broadcasting large task binary with size 1853.0 KiB\n","24/12/03 02:09:54 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n","24/12/03 02:09:57 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n","24/12/03 02:10:01 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n","24/12/03 02:10:06 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n","24/12/03 02:10:10 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n","24/12/03 02:11:03 WARN DAGScheduler: Broadcasting large task binary with size 1308.5 KiB\n","24/12/03 02:11:09 WARN DAGScheduler: Broadcasting large task binary with size 1830.1 KiB\n","24/12/03 02:11:14 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n","24/12/03 02:11:21 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n","24/12/03 02:11:55 WARN DAGScheduler: Broadcasting large task binary with size 1308.5 KiB\n","24/12/03 02:12:01 WARN DAGScheduler: Broadcasting large task binary with size 1830.1 KiB\n","24/12/03 02:12:07 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n","24/12/03 02:12:13 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n","24/12/03 02:12:20 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/12/03 02:12:29 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n","24/12/03 02:12:38 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n","24/12/03 02:12:48 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n","24/12/03 02:12:58 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n","24/12/03 02:14:16 WARN DAGScheduler: Broadcasting large task binary with size 1271.3 KiB\n","24/12/03 02:14:24 WARN DAGScheduler: Broadcasting large task binary with size 1798.6 KiB\n","24/12/03 02:14:32 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n","24/12/03 02:14:42 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n","24/12/03 02:14:53 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n","24/12/03 02:15:38 WARN DAGScheduler: Broadcasting large task binary with size 1271.3 KiB\n","24/12/03 02:15:46 WARN DAGScheduler: Broadcasting large task binary with size 1798.6 KiB\n","24/12/03 02:15:54 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n","24/12/03 02:16:04 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n","24/12/03 02:16:14 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n","24/12/03 02:16:26 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n","24/12/03 02:16:38 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n","24/12/03 02:16:53 WARN DAGScheduler: Broadcasting large task binary with size 9.0 MiB\n","24/12/03 02:17:10 WARN DAGScheduler: Broadcasting large task binary with size 10.8 MiB\n","24/12/03 02:17:28 WARN DAGScheduler: Broadcasting large task binary with size 12.4 MiB\n","24/12/03 02:18:22 WARN DAGScheduler: Broadcasting large task binary with size 1153.6 KiB\n","24/12/03 02:18:25 WARN DAGScheduler: Broadcasting large task binary with size 1528.4 KiB\n","24/12/03 02:18:28 WARN DAGScheduler: Broadcasting large task binary with size 1954.8 KiB\n","24/12/03 02:18:49 WARN DAGScheduler: Broadcasting large task binary with size 1153.6 KiB\n","24/12/03 02:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1528.4 KiB\n","24/12/03 02:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1954.8 KiB\n","24/12/03 02:18:58 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/12/03 02:19:01 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n","24/12/03 02:19:05 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n","24/12/03 02:19:09 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n"]},{"name":"stderr","output_type":"stream","text":["24/12/03 02:19:14 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n","24/12/03 02:20:08 WARN DAGScheduler: Broadcasting large task binary with size 1304.3 KiB\n","24/12/03 02:20:13 WARN DAGScheduler: Broadcasting large task binary with size 1824.3 KiB\n","24/12/03 02:20:19 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/12/03 02:20:25 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n","24/12/03 02:20:58 WARN DAGScheduler: Broadcasting large task binary with size 1304.3 KiB\n","24/12/03 02:21:04 WARN DAGScheduler: Broadcasting large task binary with size 1824.3 KiB\n","24/12/03 02:21:09 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n","24/12/03 02:21:16 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n","24/12/03 02:21:23 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/12/03 02:21:30 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n","24/12/03 02:21:39 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n","24/12/03 02:21:48 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n","24/12/03 02:21:58 WARN DAGScheduler: Broadcasting large task binary with size 8.4 MiB\n","24/12/03 02:23:15 WARN DAGScheduler: Broadcasting large task binary with size 1272.2 KiB\n","24/12/03 02:23:23 WARN DAGScheduler: Broadcasting large task binary with size 1840.9 KiB\n","24/12/03 02:23:32 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n","24/12/03 02:23:41 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n","24/12/03 02:23:52 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n","24/12/03 02:24:37 WARN DAGScheduler: Broadcasting large task binary with size 1272.2 KiB\n","24/12/03 02:24:45 WARN DAGScheduler: Broadcasting large task binary with size 1840.9 KiB\n","24/12/03 02:24:54 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n","24/12/03 02:25:03 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n","24/12/03 02:25:13 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n","24/12/03 02:25:26 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n","24/12/03 02:25:39 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n","24/12/03 02:25:54 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n","24/12/03 02:26:11 WARN DAGScheduler: Broadcasting large task binary with size 10.5 MiB\n","24/12/03 02:26:29 WARN DAGScheduler: Broadcasting large task binary with size 12.2 MiB\n","24/12/03 02:27:40 WARN DAGScheduler: Broadcasting large task binary with size 1241.9 KiB\n","24/12/03 02:27:51 WARN DAGScheduler: Broadcasting large task binary with size 1798.4 KiB\n","24/12/03 02:28:03 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n","24/12/03 02:28:16 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n","24/12/03 02:28:30 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n","24/12/03 02:28:47 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n","24/12/03 02:29:06 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n","24/12/03 02:29:26 WARN DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n","24/12/03 02:29:49 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n","24/12/03 02:30:14 WARN DAGScheduler: Broadcasting large task binary with size 13.9 MiB\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Root Mean Squared Error (RMSE): 2.375414639919392\n","Mean Absolute Error (MAE): 1.8340007179369966\n","R-squared (R²): 0.446477903625073\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 750:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------------+------+------------------+\n","|movie                     |rating|prediction        |\n","+--------------------------+------+------------------+\n","|10 Cloverfield Lane (2016)|1.0   |4.190179660484369 |\n","|10 Cloverfield Lane (2016)|1.0   |3.4142547503966587|\n","|10 Cloverfield Lane (2016)|1.0   |3.7461223948824096|\n","|10 Cloverfield Lane (2016)|1.0   |2.739110083093564 |\n","|10 Cloverfield Lane (2016)|1.0   |3.7166856662901853|\n","|10 Cloverfield Lane (2016)|1.0   |3.516396463802042 |\n","|10 Cloverfield Lane (2016)|1.0   |3.9018494821458334|\n","|10 Cloverfield Lane (2016)|1.0   |4.747633098753778 |\n","|10 Cloverfield Lane (2016)|1.0   |5.550629172790054 |\n","|10 Cloverfield Lane (2016)|1.0   |5.418605507464043 |\n","+--------------------------+------+------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["#RandomForestRegressor\n","rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\")\n","\n","#split data into training and test sets\n","train_data, test_data = sdf.randomSplit([0.7, 0.3], seed=42)\n","\n","#set up cross-validation with hyperparameter tuning\n","paramGrid = ParamGridBuilder() \\\n","    .addGrid(rf.numTrees, [10, 20, 30]) \\\n","    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n","    .build()\n","\n","\n","#evaluate the model\n","evaluator_rmse = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n","evaluator_mae = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"mae\")\n","evaluator_r2 = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"r2\")\n","\n","cv = CrossValidator(estimator=rf,\n","                    estimatorParamMaps=paramGrid,\n","                    evaluator=evaluator_rmse,  # Evaluator for RMSE\n","                    numFolds=3)\n","\n","#train the model\n","rf_model = cv.fit(train_data)\n","\n","#make predictions on the test data\n","predictions = rf_model.transform(test_data)\n","\n","\n","rmse = evaluator_rmse.evaluate(predictions)\n","mae = evaluator_mae.evaluate(predictions)\n","r2 = evaluator_r2.evaluate(predictions)\n","\n","print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n","print(f\"Mean Absolute Error (MAE): {mae}\")\n","print(f\"R-squared (R²): {r2}\")\n","\n","#sample predictions\n","predictions.select(\"movie\",\"rating\", \"prediction\").show(10, truncate=False)"]},{"cell_type":"code","execution_count":9,"id":"3abb366a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Feature Importances: \n","Column<'movie'>: 0.006237457785416196\n","Column<'rating'>: 4.669557785406666e-05\n","Column<'review_date'>: 0.005325841866644272\n","Column<'spoiler_tag'>: 0.0019276701435910317\n","Column<'review_summary_sentiment'>: 0.008825961383685627\n","Column<'review_detail_sentiment'>: 3.704670377742539e-05\n","Column<'movie_index'>: 0.0022863716768154667\n","Column<'movie_vector'>: 0.0006293659283374953\n","Column<'features'>: 0.002423454561324252\n"]},{"name":"stderr","output_type":"stream","text":["24/12/03 03:16:56 WARN TaskSetManager: Stage 762 contains a task of very large size (1100 KiB). The maximum recommended task size is 1000 KiB.\n","                                                                                \r"]}],"source":["best_model = rf_model.bestModel  # Best model after cross-validation\n","\n","#Extract feature importances\n","feature_importances = best_model.featureImportances\n","\n","#Print the feature importances\n","print(\"Feature Importances: \")\n","for feature, importance in zip(sdf, feature_importances):\n","    print(f\"{feature}: {importance}\")\n","\n","#Save the trained model to a location \n","best_model.save(\"gs://imdbreviews-bucket/models/imdb_model\")"]},{"cell_type":"code","execution_count":6,"id":"a7b8f527","metadata":{},"outputs":[{"ename":"AnalysisException","evalue":"[PATH_ALREADY_EXISTS] Path gs://imdbreviews-bucket/models/rating_predictions already exists. Set mode as \"overwrite\" to overwrite the existing path.","output_type":"error","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)","Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Save the predictions to models folder\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmovie\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrating\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgs://imdbreviews-bucket/models/rating_predictions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n","File \u001B[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:1721\u001B[0m, in \u001B[0;36mDataFrameWriter.parquet\u001B[0;34m(self, path, mode, partitionBy, compression)\u001B[0m\n\u001B[1;32m   1719\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpartitionBy(partitionBy)\n\u001B[1;32m   1720\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_opts(compression\u001B[38;5;241m=\u001B[39mcompression)\n\u001B[0;32m-> 1721\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n","File \u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n","File \u001B[0;32m/usr/lib/spark/python/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n","\u001B[0;31mAnalysisException\u001B[0m: [PATH_ALREADY_EXISTS] Path gs://imdbreviews-bucket/models/rating_predictions already exists. Set mode as \"overwrite\" to overwrite the existing path."]}],"source":["#Save the predictions to models folder\n","predictions.select(\"movie\",\"rating\", \"prediction\").write.parquet(\"gs://imdbreviews-bucket/models/rating_predictions\")"]},{"cell_type":"code","execution_count":null,"id":"a5d03d6f","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}